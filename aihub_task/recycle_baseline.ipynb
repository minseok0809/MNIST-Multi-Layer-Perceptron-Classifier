{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 재활용품 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[재활용품 분류 및 선별 데이터](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=71362)\n",
        "<br>[재활용품 분류](https://aifactory.space/task/2637/overview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G8-r8TM7aoJB"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "import torch\n",
        "import sys\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import glob\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "32hd135Xayy4"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(123) # Seed 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWO3LMoca1f2",
        "outputId": "f443f8e7-137d-443c-be80-8c15059d0ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 2.1.0+cu121  Device: cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "O6Tvv-PnnVjq"
      },
      "outputs": [],
      "source": [
        "x_train_path = 'data/train.zip'\n",
        "y_train_path = 'data/train_y.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "directory_to_extract_to = x_train_path[:-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  data/train.zip\n",
            "replace data/train/100528@5_01002_220809_P1_T1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "if not os.path.exists(directory_to_extract_to):\n",
        "  !unzip {x_train_path} -d {directory_to_extract_to}\n",
        "\"\"\"\n",
        "\n",
        "!unzip {'data/train.zip'} -d {'data/train'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc1HRG2ia4W2",
        "outputId": "2bb3b406-b5cd-489f-d84f-ddd93bff43b9"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "\n",
        "data_transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "                                             transforms.ToTensor()])\n",
        "\n",
        "# Define and map the class label\n",
        "# It would be better to sort the class label names alphabetically\n",
        "class_labels = [\"battery\",\"can\",\"glass\",\"light\",\"paper\"]\n",
        "class_labels_map = {}\n",
        "for indx, label in enumerate(class_labels):\n",
        "  class_labels_map[str(indx)] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2N3_rmf8bIkQ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "class CustomDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, class_list, transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.class_list = class_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(directory_to_extract_to+'/'+self.df.path[index])\n",
        "        label = self.class_list.index(self.df.label[index])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "train_data_object = CustomDataSet(y_train_path, class_labels, data_transform)\n",
        "\n",
        "# Now lets use Data loader to load the data in batches\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        train_data_object,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJxA905NbKbB",
        "outputId": "7ece0005-845a-42ee-933e-7d485b75281d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet34(pretrained = True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3V4oUkDbNLB",
        "outputId": "aeb70c2e-329a-425b-9bbe-b19a564cebad"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, epoch, log_interval):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (image, label) in enumerate(tqdm.tqdm(train_loader)):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        correct += (predicted == label).sum()\n",
        "        total += len(label)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \"\"\"\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "            epoch, batch_idx * len(image),\n",
        "            len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
        "            loss.item()))\n",
        "        \"\"\"\n",
        "    accuracy = round((correct.float() / total).item(), 4)\n",
        "\n",
        "    print(\"Train Epoch: {}\\tTrain Loss: {:.6f}\\tTrain Accuracy: {:.6f}\".format(\n",
        "        epoch, loss.item(), accuracy))\n",
        "\n",
        "    torch.save(model, 'model_' + str(epoch) + '.pth')\n",
        "\n",
        "EPOCHS = 3\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, epoch, log_interval = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgPeeJTobN_F",
        "outputId": "6dd0733a-28d1-42d2-9240-a3443b288b02"
      },
      "outputs": [],
      "source": [
        "x_test_path = 'data/test.zip'\n",
        "y_pred_save_path = 'y_pred.csv'\n",
        "\n",
        "directory_to_extract_to_test = x_test_path[:-4]\n",
        "\n",
        "if not os.path.exists(directory_to_extract_to_test):\n",
        "  !unzip {x_test_path} -d {directory_to_extract_to_test}\n",
        "\n",
        "\n",
        "data_transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "                                             transforms.ToTensor()])\n",
        "\n",
        "# Define and map the class label\n",
        "# It would be better to sort the class label names alphabetically\n",
        "class_labels = [\"battery\",\"can\",\"glass\",\"light\",\"paper\"]\n",
        "class_labels_map = {}\n",
        "for indx, label in enumerate(class_labels):\n",
        "  class_labels_map[str(indx)] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "NLxn7G_kbtq7"
      },
      "outputs": [],
      "source": [
        "class CustomDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, class_list, transform=None):\n",
        "        self.df = glob.glob(directory_to_extract_to_test + \"/*.jpg\")\n",
        "        self.transform = transform\n",
        "        self.class_list = class_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #print(self.df[index])\n",
        "        name = self.df[index]\n",
        "        image = Image.open(name)\n",
        "        path = name[len(str(directory_to_extract_to_test + \"/\")):]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, path\n",
        "\n",
        "test_data_object = CustomDataSet(class_labels, data_transform)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Now lets use Data loader to load the data in batches\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        test_data_object,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sawKCrXCbyTi",
        "outputId": "0f812ee3-9d72-4861-a654-03f5a86b506f"
      },
      "outputs": [],
      "source": [
        "model = models.resnet34(pretrained = True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "BXaQoR2XbztB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:21<00:00,  2.11s/it]\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    df = pd.DataFrame({\"path\":[], \"pred\":[]})\n",
        "    with torch.no_grad():\n",
        "        for image, name in tqdm.tqdm(test_loader):\n",
        "            image = image.to(DEVICE)\n",
        "            name = name#.to(DEVICE)\n",
        "            output = model(image)\n",
        "            \n",
        "            for i in range(len(image)):\n",
        "                #prediction.append(name[i].cpu())\n",
        "                #prediction.append(output[i].argmax().cpu().numpy())\n",
        "                prediction = output[0].argmax().cpu().numpy()\n",
        "                df2 = pd.DataFrame({\"path\":[name[i]], \"pred\":[prediction]})\n",
        "                df = pd.concat([df, df2], ignore_index=True)\n",
        "\n",
        "    #pd.DataFrame(prediction).to_csv(y_pred_save_path, header=False, index=False)\n",
        "    df.loc[df['pred'] ==0, 'pred'] = 'battery'\n",
        "    df.loc[df['pred'] ==1, 'pred'] = 'can'\n",
        "    df.loc[df['pred'] ==2, 'pred'] = 'glass'\n",
        "    df.loc[df['pred'] ==3, 'pred'] = 'light'\n",
        "    df.loc[df['pred'] ==4, 'pred'] = 'paper'\n",
        "    y_pred_save_path = 'y_pred.csv'\n",
        "    df.to_csv(y_pred_save_path, index=False)\n",
        "    y_pred_labels = np.array(predictions)\n",
        "    y_pred_save_path = 'y_pred.npy'\n",
        "    np.save(y_pred_save_path, y_pred_labels)\n",
        "\n",
        "model_path = 'model_1.pth'\n",
        "model = torch.load(model_path)\n",
        "output = evaluate(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

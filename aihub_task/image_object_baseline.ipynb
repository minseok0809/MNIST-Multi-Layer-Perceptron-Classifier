{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 이미지에서 객체 라벨 인식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJPxCkOEE-EE",
        "outputId": "f0bc8675-bb58-4258-9c73-9e37f4ab34a0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import json\n",
        "import torchvision\n",
        "import sys\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "classes_of_interest = [\"object\",\"target\"]\n",
        "class_name_to_label = {class_name: idx for idx, class_name in enumerate(classes_of_interest)}\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, npy_path, annotation_file):\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            self.annotations = json.load(f)\n",
        "        self.images_dict = np.load(npy_path, allow_pickle=True).item()\n",
        "        self.image_ids = list(self.images_dict.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.image_ids[idx]\n",
        "        image = Image.fromarray(self.images_dict[image_id]).convert(\"RGB\")\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for anno in self.annotations[image_id]:\n",
        "            boxes.append(anno[\"bbox\"])\n",
        "            labels.append(anno[\"class\"])\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "\n",
        "        labels = [class_name_to_label[label] for label in labels]\n",
        "        labels = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        image = F.to_tensor(image)\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"image_id\": torch.tensor([idx])\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    return images, targets\n",
        "\n",
        "def get_model(num_classes: int):\n",
        "    model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1)\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "def main(num_epochs, batch_size):\n",
        "    train_npy_path = 'data/train_image.npy'\n",
        "    label_path = 'data/train_label.json'\n",
        "    weight_save_path = 'data/weights_00.pth'\n",
        "\n",
        "    dataset = CustomDataset(train_npy_path, label_path)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "    num_classes = len(classes_of_interest) + 1\n",
        "    model = get_model(num_classes)\n",
        "    model.to('cuda')\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.008, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        model.train()\n",
        "        iteration = 0\n",
        "        for images, targets in tqdm.tqdm(data_loader):\n",
        "            iteration += 1\n",
        "            images = [img.to('cuda') for img in images]\n",
        "            targets = [{k: v.to('cuda') for k, v in t.items()} for t in targets]\n",
        "            #print(images, targets)\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # if iteration % 10 == 0:\n",
        "                # print(f\"Epoch {epoch}/{num_epochs}, Iteration {iteration}/{len(data_loader)} Loss: {losses.item()}\")\n",
        "        print(f\"Epoch {epoch}/{num_epochs}, Loss: {round(losses.item(), 4)}\")   \n",
        "    torch.save(model.state_dict(), weight_save_path.replace('00', str(epoch)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:20<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.1147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:20<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Loss: 0.093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:20<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Loss: 0.0376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:21<00:00,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Loss: 0.0692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:20<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Loss: 0.0297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:20<00:00,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Loss: 0.0421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:20<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Loss: 0.0385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:21<00:00,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Loss: 0.0399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:20<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10, Loss: 0.0277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:20<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Loss: 0.0527\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 16\n",
        "main(num_epochs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import json\n",
        "import torchvision\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "classes_of_interest = [\"object\",\"target\"]\n",
        "\n",
        "transform = T.Compose([\n",
        "                        T.Resize((1080, 1920)),\n",
        "                    ])\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, npy_path, transform=None):\n",
        "        self.images_dict = np.load(npy_path, allow_pickle=True).item()\n",
        "        self.image_ids = list(self.images_dict.keys())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.image_ids[idx]\n",
        "        image = Image.fromarray(self.images_dict[image_id]).convert(\"RGB\")\n",
        "        image = F.to_tensor(image)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, image_id\n",
        "\n",
        "def get_model(num_classes: int):\n",
        "    model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1)\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = {}\n",
        "    with torch.no_grad():\n",
        "        for images, image_ids in dataloader:\n",
        "            images = [img.to(device) for img in images]\n",
        "            outputs = model(images)\n",
        "            for idx, output in enumerate(outputs):\n",
        "                image_id = image_ids[idx]\n",
        "                boxes = output['boxes'].cpu().numpy().tolist()\n",
        "                scores = output['scores'].cpu().numpy().tolist()\n",
        "                labels = output['labels'].cpu().numpy().tolist()\n",
        "                predictions[image_id] = [\n",
        "                    {\n",
        "                        \"class\": classes_of_interest[label],\n",
        "                        \"bbox\": box,\n",
        "                        \"score\": score\n",
        "                    }\n",
        "                    for label, box, score in zip(labels, boxes, scores)\n",
        "                ]\n",
        "    return predictions\n",
        "\n",
        "def main(batch_size):\n",
        "    model_weights = 'data/weights_10.pth'\n",
        "    test_npy_path = 'data/test_image.npy'\n",
        "    output = 'data/submit.json'\n",
        "\n",
        "    num_classes = len(classes_of_interest) + 1\n",
        "    model = get_model(num_classes)\n",
        "    model.load_state_dict(torch.load(model_weights))\n",
        "    model = model.to('cuda')\n",
        "\n",
        "    test_dataset = CustomDataset(test_npy_path, transform=transform)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    pred_dict = predict(model, test_dataloader, 'cuda')\n",
        "\n",
        "    with open(output, 'w') as f:\n",
        "        json.dump(pred_dict, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "main(batch_size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
